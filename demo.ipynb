{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_lg\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_lg.load()\n",
    "import requests\n",
    "import json\n",
    "#nlp = spacy.load(\"/Users/praveenkumarrajendran/codebase/air/en_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "def get_full_text(token):\n",
    "    \n",
    "    full_text = \"\"\n",
    "    for child_token in token.children:\n",
    "        full_text = full_text + \" \"+child_token.text\n",
    "    full_text = full_text + \" \"+ token.text\n",
    "    text_tokens = full_text.split(\" \")\n",
    "    filterd_tokens = []\n",
    "    for token in text_tokens:\n",
    "        if(token not in stopwords):\n",
    "            filterd_tokens.append(token)\n",
    "    full_text = \" \".join(filterd_tokens)\n",
    "    return full_text\n",
    "\n",
    "\n",
    "def extract_event_attribute(event, token, side):\n",
    "\n",
    "    full_text = get_full_text(token);\n",
    "\n",
    "    isLeft = (side == \"left\")\n",
    "    ent_type = token.ent_type_;\n",
    "    if(ent_type == \"\"):\n",
    "        extract_event_attribute_from_list(event, token.children, side)\n",
    "    if(ent_type == 'DATE'):\n",
    "        event['date'].add(full_text)\n",
    "    elif(ent_type == 'LOC'):\n",
    "#         print(\"Going to add token::\"+token.text)\n",
    "        event['location'].add(token.text)\n",
    "    elif(ent_type == 'GPE'):\n",
    "#         event['country'] = full_text\n",
    "        event['location'].add(token.text)\n",
    "    elif(ent_type == 'CARDINAL'):\n",
    "        event['fatalities'] = full_text\n",
    "    elif(ent_type == 'PERSON'):\n",
    "        attribute_name = \"actor2\" if \"actor1\" in event else \"actor1\"\n",
    "        event[attribute_name] = full_text\n",
    "        for child in token.children:\n",
    "            if(child.dep_ == 'nummod'):\n",
    "                extract_event_attribute(event, child, side)\n",
    "    elif(ent_type == 'ORG'):\n",
    "#         attribute_name = \"org2\" if \"org1\" in event else \"org1\"\n",
    "        event['org'].add(full_text)\n",
    "#         event['org'].add(full_text)\n",
    "        for child in token.children:\n",
    "            if(child.dep_ == 'nummod'):\n",
    "                extract_event_attribute(event, child, side)\n",
    "    \n",
    "    \n",
    "\n",
    "def extract_event_attribute_from_list(event, tokens, side):\n",
    "    \n",
    "    entity_type=\"\"\n",
    "    full_text=\"\"\n",
    "    for token in tokens:\n",
    "        extract_event_attribute(event, token, side)\n",
    "\n",
    "def extract_event(doc):\n",
    "    \n",
    "    event = {}\n",
    "    event['location']=set()\n",
    "    event['date'] = set()\n",
    "    event['org'] = set()\n",
    "    for sent in doc.sents:\n",
    "        short_doc = nlp(sent.text)\n",
    "#         for ent in short_doc.ents:\n",
    "#             print(ent.text+\"::\"+ent.label_)\n",
    "        for token in short_doc:\n",
    "            dependency = token.dep_\n",
    "            if(dependency == \"ROOT\"):\n",
    "                for left_token in token.lefts:\n",
    "                    child_dep = left_token.dep_\n",
    "                    if(child_dep in('nsubjpass', 'nsubj')):\n",
    "                        extract_event_attribute(event, left_token,'left')\n",
    "                    elif(child_dep == 'prep'):\n",
    "                        extract_event_attribute_from_list(event, left_token.rights, 'left')\n",
    "\n",
    "                for right_token in token.rights:\n",
    "                    right_child_dep = right_token.dep_\n",
    "                    full_text = get_full_text(right_token)\n",
    "                    if(right_child_dep in('attr','dobj')):\n",
    "                        extract_event_attribute(event, right_token,'right')\n",
    "                    elif(right_child_dep == 'prep'):\n",
    "                        extract_event_attribute_from_list(event, right_token.rights, 'right')\n",
    "                    elif(right_child_dep == 'agent'):\n",
    "                        extract_event_attribute_from_list(event, right_token.children, 'right')\n",
    "\n",
    "            elif(dependency == \"pobj\"):\n",
    "                extract_event_attribute(event,token,'right')\n",
    "#         displacy.render(nlp(str(short_doc)), style='dep', jupyter = True, options = {'distance': 120})\n",
    "    return event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_tokens = set()\n",
    "violence_doc = nlp(\"crime kill murder death died criminal convict attack assault assaulted harrasment offence illegal attacker attacked\")\n",
    "for token in violence_doc:\n",
    "    violence_tokens.add(token.lemma_)\n",
    "\n",
    "protest_tokens = set()\n",
    "protest_doc = nlp(\"protest protester agitation perpetrators rioters riot discord rebellion activist activism demonstration demonstrating resentment grievances agitators ban fast march dharna mourn strike\")\n",
    "for token in protest_doc:\n",
    "    protest_tokens.add(token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare lemmatised tokens\n",
    "\n",
    "def classify_doc_topic(doc):\n",
    "    docTokens = set()\n",
    "    topic = 'Unclassified'\n",
    "    for token in doc:\n",
    "        docTokens.add(token.lemma_)\n",
    "    violence_match = len(docTokens.intersection(violence_tokens))\n",
    "    protest_match = len(docTokens.intersection(protest_tokens))\n",
    "\n",
    "    if(violence_match > 0 and protest_match > 0):\n",
    "        if(violence_match > protest_match):\n",
    "            topic = 'Violence against Civilians'\n",
    "        else:\n",
    "            topic = 'Riots/Protests'\n",
    "    elif (violence_match > 0):\n",
    "        topic = 'Violence against Civilians'\n",
    "    elif (protest_match > 0):\n",
    "        topic = 'Riots/Protests'    \n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "def summarise_event(doc):\n",
    "    mytokens = [token.text for token in doc]\n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text not in stopwords:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "\n",
    "    # print(word_frequencies)\n",
    "    maximum_frequency = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "            word_frequencies[word] = (word_frequencies[word]/maximum_frequency)\n",
    "    # word_frequencies\n",
    "    sentence_list = [ sentence for sentence in doc.sents ]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_list:\n",
    "            for word in sent:\n",
    "                if word.text.lower() in word_frequencies.keys():\n",
    "                    if len(sent.text.split(' ')) < 30:\n",
    "                        if sent not in sentence_scores.keys():\n",
    "                            sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                        else:\n",
    "                            sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "    # print(sentence_scores)\n",
    "    from heapq import nlargest\n",
    "    summarized_sentences = nlargest(3, sentence_scores, key=sentence_scores.get)\n",
    "    # summarized_sentences\n",
    "    # for w in summarized_sentences:\n",
    "    #     print(w.text)\n",
    "    final_sentences = [ w.text for w in summarized_sentences ]\n",
    "    summary = ' '.join(final_sentences)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_country_of_interest(addresses):\n",
    "    for address in addresses:\n",
    "        area_name = address['long_name']\n",
    "        address_types = address['types']\n",
    "        if ('country' in address_types):\n",
    "            if(area_name in ['India','Indonesia','Thailand']):\n",
    "                return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_location_data(possible_locations):\n",
    "    location_data = {}\n",
    "    for location in possible_locations:\n",
    "        response = requests.get('https://maps.googleapis.com/maps/api/geocode/json?address='+location+'&key=AIzaSyAQ4fdgmwd5tNsjI50ZqTIO0LURkXccxzc')\n",
    "        responseJson = json.loads(response.text)\n",
    "        results = responseJson['results']\n",
    "        if(len(results) > 0):\n",
    "            firstResult = results[0]\n",
    "            addresses = firstResult['address_components']\n",
    "#             if the name is the same for admin_level_1, admin_level_2, admin_level_3, then take only admin_level_1\n",
    "            for address in addresses:\n",
    "                if(not is_country_of_interest(addresses)):\n",
    "                    continue\n",
    "#                 print(address)\n",
    "                area_name = address['long_name']\n",
    "                address_types = address['types']\n",
    "                if ('country' in address_types):\n",
    "                    location_data['country'] = area_name\n",
    "                elif ('administrative_area_level_1' in address_types):\n",
    "                    location_data['administrative_area_level_1'] = area_name\n",
    "                elif ('administrative_area_level_2' in address_types \n",
    "                      and 'administrative_area_level_2' not in location_data):\n",
    "                    location_data['administrative_area_level_2'] = area_name\n",
    "                elif('locality' in address_types\n",
    "                    and 'administrative_area_level_3' not in location_data):\n",
    "                    location_data['administrative_area_level_3'] = area_name\n",
    "                elif('sublocality' in address_types\n",
    "                    and 'administrative_area_level_4' not in location_data):\n",
    "                    location_data['administrative_area_level_4'] = area_name\n",
    "#             print(location_data)\n",
    "                if(len(location_data) == 5):\n",
    "                   break\n",
    "    return location_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_organization_data(possible_organizations):\n",
    "    organization_data = {}\n",
    "    for org in possible_organizations:\n",
    "        org = org.strip()\n",
    "        org = \"+\".join(org.split(\" \"))\n",
    "        print('Org is::'+org)\n",
    "        response = requests.get('https://kgsearch.googleapis.com/v1/entities:search?query='+org+'&key=AIzaSyAQ4fdgmwd5tNsjI50ZqTIO0LURkXccxzc&limit=5&indent=True')\n",
    "        responseJson = json.loads(response.text)\n",
    "        if('itemListElement' in responseJson):\n",
    "            items = responseJson['itemListElement']\n",
    "            if(len(items) > 0):\n",
    "                firstResult = items[0]['result']\n",
    "                org_name = firstResult['name']\n",
    "                types = firstResult['@type']\n",
    "                if('Organization' in types):\n",
    "                    if(len(organization_data) == 0):\n",
    "                        organization_data['org1'] = org_name\n",
    "                    else: \n",
    "                        organization_data['org2'] = org_name\n",
    "            if(len(organization_data) == 2):\n",
    "                break\n",
    "    return organization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder\n",
    "import datetime\n",
    "\n",
    "weekdays = ['monday','tuesday','wednesday','thursday','friday','saturday','sunday']\n",
    "\n",
    "# from the list of date entities from the article, \n",
    "# - finds the date that is at least distance from the published date\n",
    "# - converts 'day' to dates relative to the published date\n",
    "# - if there are no date entities, assumes the published date to be event date\n",
    "\n",
    "def get_event_date(dates, published_date_str):\n",
    "    \n",
    "    published_date = datetime.datetime.strptime(published_date_str, \"%Y-%m-%d\")\n",
    "    published_day_of_week = published_date.weekday()\n",
    "    recent_date = None\n",
    "    current_min = None\n",
    "    for date_str in dates:\n",
    "        event_date = None\n",
    "        date_str = date_str.lower()\n",
    "        for day in weekdays:\n",
    "            if(day in date_str):\n",
    "                given_day_of_week = weekdays.index(day)\n",
    "                day_diff = abs(published_day_of_week - given_day_of_week)\n",
    "                if(day_diff > 0):\n",
    "                    day_diff = 7-day_diff\n",
    "                event_date = published_date - datetime.timedelta(days = day_diff)\n",
    "        if(event_date is None):\n",
    "            dates = list(datefinder.find_dates(date_str))       \n",
    "            if(len(dates) > 0):\n",
    "                event_date = dates[0]\n",
    "        if(event_date is not None):\n",
    "            relative_day_diff = abs((published_date - event_date).days)\n",
    "            if(relative_day_diff == 0):\n",
    "                recent_date = event_date\n",
    "                break\n",
    "            else:\n",
    "                if(current_min is None or relative_day_diff < current_min):\n",
    "                    current_min = relative_day_diff\n",
    "                    recent_date = event_date\n",
    "    if(recent_date is None):\n",
    "        recent_date = published_date\n",
    "    return str(recent_date).split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org is::Communist+Party\n",
      "Org is::Ayyappa\n",
      "Org is::Sabarimala+Action+Council\n",
      "Org is::LDF\n",
      "Org is::K\n",
      "Org is::(+Photo+:+)+With+,+activists+PTI\n",
      "Org is::Secretariat\n",
      "Org is::India(Marxist)-led+Left+Democratic+Front\n",
      "Org is::P\n",
      "Org is::Kolathur+Adavaitha+Ashram\n",
      "Org Data\n",
      "{'org1': 'Communist Party of India (Marxist)'}\n",
      "Location data\n",
      "{'administrative_area_level_1': 'Kerala', 'country': 'India', 'administrative_area_level_3': 'Thiruvananthapuram', 'administrative_area_level_2': 'Thiruvananthapuram'}\n",
      "Org is::\n",
      "Org is::Guwahati\n",
      "Org is::Asom\n",
      "Org is::BJP\n",
      "Org is::Gana\n",
      "Org is::Ambari\n",
      "Org is::AGP\n",
      "Org is::incumbent+BJP\n",
      "Org is::BJP+AGP\n",
      "Org Data\n",
      "{'org1': 'Bharatiya Janata Party'}\n",
      "Location data\n",
      "{'administrative_area_level_1': 'Assam', 'country': 'India', 'administrative_area_level_3': 'Guwahati', 'administrative_area_level_2': 'Kamrup'}\n",
      "Org is::Bhartiya+Kisan+BKU+Union\n",
      "Org is::Haryana+Government\n",
      "Org is::A\n",
      "Org Data\n",
      "{'org1': 'Haryana', 'org2': 'Serie A'}\n",
      "Location data\n",
      "{'administrative_area_level_3': 'Ambala', 'administrative_area_level_2': 'Ambala', 'administrative_area_level_1': 'Haryana', 'country': 'India'}\n",
      "Org is::YASIN\n",
      "Org is::NRC\n",
      "Org is::(+)+NRC\n",
      "Org Data\n",
      "{'org1': 'Nuclear Regulatory Commission', 'org2': 'Nuclear Regulatory Commission'}\n",
      "Location data\n",
      "{'administrative_area_level_3': 'Jalalpur', 'administrative_area_level_2': 'Ambedkar Nagar', 'administrative_area_level_1': 'Uttar Pradesh', 'country': 'India'}\n",
      "Org is::\n",
      "Org is::Government+Elementary+,+village+School\n",
      "Org is::Parho+Punjab\n",
      "Org is::Post+Office\n",
      "Org is::District+Education+(+Primary+)+Kumari+Officer\n",
      "Org is::Government+Multipurpose+Elementary+School\n",
      "Org is::Government+â€˜+Parho+Punjab\n",
      "Org is::The+Education+Departmnet\n",
      "Org is::Education+Department\n",
      "Org Data\n",
      "{'org1': 'United States Postal Service', 'org2': 'United States Department of Health and Human Services'}\n",
      "Org is::KCP+Nando+Group\n",
      "Org is::Thambal+,+Konjil+Academy\n",
      "Org is::All+Manipur+Muslim+Students+(+AMMSO+Organisation+Organisation\n",
      "Org is::JNIMS+Hospital\n",
      "Org is::Police+persons+Department\n",
      "Org is::JNIMS\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-3ff6e34ede07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'org'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             print(event['org'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0morg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_organization_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'org'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Org Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-258-01b80ee387aa>\u001b[0m in \u001b[0;36mget_organization_data\u001b[0;34m(possible_organizations)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mfirstResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0morg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirstResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirstResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'@type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Organization'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "final_event_map = {}\n",
    "final_event_map['org']=[]\n",
    "# final_event_map['org1']=[]\n",
    "# final_event_map['org2']=[]\n",
    "final_event_map['actor1']=[]\n",
    "final_event_map['actor2']=[]\n",
    "final_event_map['type']=[]\n",
    "final_event_map['summary']=[]\n",
    "final_event_map['date']=[]\n",
    "final_event_map['location']=[]\n",
    "\n",
    "\n",
    "# doc = nlp(\"Ghodse killed Mahatma Ghandi on Oct 2, 1947\")\n",
    "# doc = nlp(\"Ghandhi was born on October 2, 1869 to the couples Karamchand Ghandhi and Putlibai Ghandhi\")\n",
    "# doc = nlp(\"On 2nd October 1947, Godse killed Mahatma Ghandi\")\n",
    "# doc = nlp(\"On 2nd October 1947, Mahatma Ghandi was killed by Godse\")\n",
    "# doc = nlp(\"On 14 February 2019, a convoy of vehicles carrying security personnel on the Jammu Srinagar National Highway was attacked by a vehicle-borne suicide bomber at Lethpora (near Awantipora) in the Pulwama district, Jammu and Kashmir, India. The attack resulted in the deaths of 40 Central Reserve Police Force (CRPF) personnel and the attacker.The responsibility for the attack was claimed by the Pakistan-based Islamist militant group Jaish-e-Mohammed.The attacker was Adil Ahmad Dar, a local from Pulwama district, and a member of Jaish-e-Mohammed.\")\n",
    "\n",
    "url_list = ['https://www.indiatoday.in/elections/lok-sabha-2019/story/sabarimala-outfit-holds-namajapa-protest-in-kerala-1501155-2019-04-13',\n",
    "           'https://www.time8.in/massive-protest-infront-of-agp-headquarters-in-guwahati-opposing-alliance/',\n",
    "           'https://www.tribuneindia.com/news/chandigarh/farmers-protest-against-govt-demand-relief-for-crop-loss/746263.html',\n",
    "           'https://www.time8.in/assam-nrc-illegal-bangladeshis-thrashed-by-miscreants-in-cachar/',\n",
    "           'https://www.tribuneindia.com/news/chandigarh/teachers-protest-transfers-hold-deo-hostage/734787.html',\n",
    "           'http://e-pao.net/GP.asp?src=17..020419.apr19']\n",
    "\n",
    "for url in url_list:\n",
    "    article = NewsPlease.from_url(url)\n",
    "    doc = nlp(article.text)\n",
    "    published_date_str = str(article.date_publish).split(\" \")[0]\n",
    "    doc_topic = classify_doc_topic(doc)\n",
    "    if(doc_topic!=\"Unclassified\"):\n",
    "\n",
    "        event = extract_event(doc)\n",
    "        event['type'] = doc_topic\n",
    "        event_summary = summarise_event(doc)\n",
    "        event['summary'] = event_summary\n",
    "        if 'org' in event:\n",
    "#             print(event['org'])\n",
    "            org_data = get_organization_data(event['org'])\n",
    "            print(\"Org Data\")\n",
    "            print(org_data)\n",
    "            final_event_map['org'].append(org_data)\n",
    "        else:\n",
    "            final_event_map['org'].append('')\n",
    "#         else:\n",
    "#             final_event_map['org1'].append('')\n",
    "#         if 'org2' in event: \n",
    "#             final_event_map['org2'].append(event['org2'])\n",
    "#         else:\n",
    "#             final_event_map['org2'].append('')\n",
    "        if 'actor1' in event:\n",
    "            final_event_map['actor1'].append(event['actor1'])  \n",
    "        else:\n",
    "            final_event_map['actor1'].append('')\n",
    "        if 'actor2' in event:\n",
    "            final_event_map['actor2'].append(event['actor2'])\n",
    "        else:\n",
    "            final_event_map['actor2'].append('')\n",
    "        if 'date' in event:\n",
    "            final_event_map['date'].append(get_event_date(event['date'], published_date_str))\n",
    "        else:\n",
    "            final_event_map['date'].append('')\n",
    "        if 'type' in event:\n",
    "            final_event_map['type'].append(event['type'])\n",
    "        else:\n",
    "            final_event_map['type'].append('')\n",
    "        if 'summary' in event:\n",
    "            final_event_map['summary'].append(event['summary'])\n",
    "        else:\n",
    "            final_event_map['summary'].append('')\n",
    "        if 'location' in event:\n",
    "#             print(\"Final Location::\"+str(event['location']))\n",
    "            location_data = get_location_data(event['location'])\n",
    "            #do not process if country is not set, this will happen for events outside India, Thailand and Indonesia\n",
    "            if('country' not in location_data):\n",
    "                continue\n",
    "            print(\"Location data\")\n",
    "            print(location_data)\n",
    "            final_event_map['location'].append(str(location_data))\n",
    "        else:\n",
    "            final_event_map['location'].append('')\n",
    "\n",
    "# import os\n",
    "# path = '/Users/praveenkumarrajendran/codebase/air/articles' \n",
    "# for file in os.listdir( path ):\n",
    "#     file = path+\"/\"+file\n",
    "#     print(file)\n",
    "#     if file.endswith( \".txt\" ):\n",
    "#         f=open(file, 'r')  \n",
    "#         content = f.readlines()\n",
    "#         f.close() \n",
    "#         doc = nlp(content[0])\n",
    "#         # sentences = [x for x in doc.sents]\n",
    "#         # for ent in doc.ents:\n",
    "#         #     print(ent.text+\"::\"+ent.label_)\n",
    "#         doc_topic = classify_doc_topic(doc)\n",
    "#         # print(extract_event(doc))\n",
    "#         if(doc_topic!=\"Unclassified\"):\n",
    "\n",
    "#             event = extract_event(doc)\n",
    "#             print(\"Event is::\"+str(event))\n",
    "#             event['type'] = doc_topic\n",
    "#             event_summary = summarise_event(doc)\n",
    "#             event['summary'] = event_summary\n",
    "#             if 'org' in event:\n",
    "#                 print(\"Final org list\")\n",
    "#                 print(event['org'])\n",
    "#                 final_event_map['org'].append(event['org'])\n",
    "#             else:\n",
    "#                 final_event_map['org'].append('')\n",
    "# #             if 'org1' in event:\n",
    "# #                 final_event_map['org1'].append(event['org1'])\n",
    "# #             else:\n",
    "# #                 final_event_map['org1'].append('')\n",
    "# #             if 'org2' in event: \n",
    "# #                 final_event_map['org2'].append(event['org2'])\n",
    "# #             else:\n",
    "# #                 final_event_map['org2'].append('')\n",
    "#             if 'actor1' in event:\n",
    "#                 final_event_map['actor1'].append(event['actor1'])  \n",
    "#             else:\n",
    "#                 final_event_map['actor1'].append('')\n",
    "#             if 'actor2' in event:\n",
    "#                 final_event_map['actor2'].append(event['actor2'])\n",
    "#             else:\n",
    "#                 final_event_map['actor2'].append('')\n",
    "#             if 'date' in event:\n",
    "                \n",
    "#                 final_event_map['date'].append(event['date'])\n",
    "#             else:\n",
    "#                 final_event_map['date'].append('')\n",
    "#             if 'type' in event:\n",
    "#                 final_event_map['type'].append(event['type'])\n",
    "#             else:\n",
    "#                 final_event_map['type'].append('')\n",
    "#             if 'summary' in event:\n",
    "#                 final_event_map['summary'].append(event['summary'])\n",
    "#             else:\n",
    "#                 final_event_map['summary'].append('')\n",
    "#             if 'location' in event:\n",
    "#                 print(\"Location data in event\")\n",
    "#                 print(event['location'])\n",
    "#                 final_event_map['location'].append(event['location'])\n",
    "#             else:\n",
    "#                 final_event_map['location'].append('')\n",
    "# add to table\n",
    "# print events table\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(final_event_map)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')\n",
    "datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')\n",
    "print(datetime_object.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
